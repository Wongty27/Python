{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess_utils import sample_per_class, imbalance_train, get_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from result_utils import plot_curve, Result\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "image_size = 128\n",
    "batch_size = 32\n",
    "cwru_path = 'Dataset/pywt_speed/1'\n",
    "features, labels, class_names = get_dataset(cwru_path, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_path = 'Dataset/pywt_speed/0'\n",
    "x_test, y_test, _ = get_dataset(test_path, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method 1 for Fault type classification'''\n",
    "# Prepare equally sized dataset and split into 3 subsets \n",
    "x_resampled, y_resampled = sample_per_class(features, labels, 800)\n",
    "x_train, X_test, y_train, Y_test = train_test_split(x_resampled, y_resampled, train_size=0.6, random_state=7, stratify=y_resampled)\n",
    "x_val, x_test, y_val, y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=7, stratify=Y_test)\n",
    "\n",
    "# Create imbalance training dataset with 1% of original size\n",
    "x_train, y_train = imbalance_train(x_train, y_train, 0.05) \n",
    "\n",
    "# Show data distribution for each class\n",
    "Counter(y_train), Counter(y_val), Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method 2 For Speed Domain'''\n",
    "# Prepare equally sized dataset and split into 3 subsets \n",
    "x_resampled, y_resampled = sample_per_class(features, labels, 800)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_resampled, y_resampled, train_size=0.8, random_state=7, stratify=y_resampled)\n",
    "\n",
    "# Show data distribution for each class\n",
    "Counter(y_train), Counter(y_val), Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method 3'''\n",
    "# 1. Prepare equally sized dataset\n",
    "# 2. Turn into imbalanced dataset\n",
    "# 3. Split into 3 subsets\n",
    "x_resampled, y_resampled = sample_per_class(features, labels, 4700)\n",
    "x_resampled, y_resampled = imbalance_train(x_resampled, y_resampled, 0.01)\n",
    "x_train, X_test, y_train, Y_test = train_test_split(x_resampled, y_resampled, train_size=0.6, random_state=7, stratify=y_resampled)\n",
    "x_val, x_test, y_val, y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=7, stratify=Y_test)\n",
    "(Counter(y_train), Counter(y_val), Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add fake data'''\n",
    "def augmentation(x_real, y_real, fake_root_dir, image_size, sample_size):\n",
    "    '''Augment imbalanced dataset with synthetic samples.'''\n",
    "    fake_x, fake_y, _ = get_dataset(fake_root_dir, image_size)\n",
    "    fx_resampled, fy_resampled = sample_per_class(fake_x, fake_y, sample_size)\n",
    "    fx_reshaped = fx_resampled.reshape((-1, image_size*image_size*3))\n",
    "\n",
    "    x_reshaped = x_real.reshape((-1, image_size*image_size*3))\n",
    "\n",
    "    augmented_x = np.concatenate((x_reshaped, fx_reshaped))\n",
    "    augmented_y = np.concatenate((y_real, fy_resampled))\n",
    "    \n",
    "    augmented_x = augmented_x.reshape((len(augmented_x), image_size, image_size, 3))\n",
    "    print(f'Augmented dataset distribution: {Counter(augmented_y)}')\n",
    "    return augmented_x, augmented_y\n",
    "\n",
    "x_train, y_train = augmentation(x_train, y_train, 'Dataset/fake_cwt', image_size, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize dataset\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.title(labels[i].numpy())\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: ConvNet\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(32, (3, 3), input_shape=(128, 128, 3),\n",
    "                            padding=\"same\"),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        # keras.layers.Conv2D(96, (3, 3), padding=\"same\"),\n",
    "        # keras.layers.ReLU(),\n",
    "        # keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.GlobalAveragePooling2D(),      \n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(4, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_path = \"./Results/cwru/cwt/hp1_400\"\n",
    "\n",
    "# def myprint(s):\n",
    "#     with open(f'{checkpoint_path}/summary.txt','a') as f:\n",
    "#         print(s, file=f)\n",
    "\n",
    "# model.summary(print_fn=myprint)\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'{checkpoint_path}/trained',\n",
    "    save_weights_only=False,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "early_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    )\n",
    "\n",
    "cb = [\n",
    "    checkpoint_callback, \n",
    "    # early_callback\n",
    "    ]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_val, y_val), callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f'{checkpoint_path}/history.csv'\n",
    "with open(history_csv, mode='w') as f:\n",
    "    history_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(history, checkpoint_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = 'Results/cwru/cwt/imbalanced_50'\n",
    "loaded_model = keras.models.load_model(f'{checkpoint_path}/trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with testing dataset\n",
    "result = Result(x_test, y_test, class_names, loaded_model, checkpoint_path, 'hp0_400')\n",
    "result.write_report()\n",
    "result.plot_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
